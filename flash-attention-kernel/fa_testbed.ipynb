{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3], dtype=torch.float16)\n",
    "b = torch.tensor([1, 2, 3], dtype=torch.float16)\n",
    "c = torch.tensor([True, True, True])\n",
    "\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0900, 0.2448, 0.6650, 0.0900, 0.2448, 0.6650], dtype=torch.float16),\n",
       " tensor([0.0043, 0.0116, 0.0316, 0.0858, 0.2332, 0.6338], dtype=torch.float16))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_valid_softmax(x: torch.Tensor):\n",
    "    return torch.sum(x, dim=0).item() == 1\n",
    "\n",
    "\n",
    "def are_tensors_equal(a, b):\n",
    "    if all(a == b):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6], dtype=torch.float16)\n",
    "a1, a2 = torch.split(a, 3) # this creates [1, 2, 3] and [4, 5, 6]\n",
    "\n",
    "s1 = f.softmax(a1, dim=0)\n",
    "s2 = f.softmax(a2, dim=0)\n",
    "s = f.softmax(a, dim=0)\n",
    "\n",
    "s_merged = torch.concat((s1, s2))\n",
    "s_merged, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(is_valid_softmax(s_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(is_valid_softmax(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 61000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([60928., 60928.], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([a, a], dtype=torch.bfloat16)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1: Simple increasing sequence\n",
      "\n",
      "Input sequence: [1. 3. 5.]\n",
      "\n",
      "Running maximum (mᵢ): [1. 3. 5.]\n",
      "Global maximum (mₙ): 5.0\n",
      "\n",
      "Step-by-step comparison:\n",
      "idx | x[i] |    dᵢ   |   dᵢ'   | Scale Factor\n",
      "--------------------------------------------------\n",
      "  0 |  1.00 |  0.0183 |  1.0000 | 54.5981\n",
      "  1 |  3.00 |  0.1537 |  1.1353 |  7.3891\n",
      "  2 |  5.00 |  1.1537 |  1.1537 |  1.0000\n",
      "\n",
      "Verification:\n",
      "Final dₙ:          1.153651\n",
      "Final dₙ' × scale: 1.153651\n",
      "Match: True\n",
      "\n",
      "Example 2: Varying sequence\n",
      "\n",
      "Input sequence: [3 1 4 7 2]\n",
      "\n",
      "Running maximum (mᵢ): [3. 3. 4. 7. 7.]\n",
      "Global maximum (mₙ): 7\n",
      "\n",
      "Step-by-step comparison:\n",
      "idx | x[i] |    dᵢ   |   dᵢ'   | Scale Factor\n",
      "--------------------------------------------------\n",
      "  0 |  3.00 |  0.0183 |  1.0000 | 54.5981\n",
      "  1 |  1.00 |  0.0208 |  1.1353 | 54.5981\n",
      "  2 |  4.00 |  0.0706 |  1.4177 | 20.0855\n",
      "  3 |  7.00 |  1.0706 |  1.0706 |  1.0000\n",
      "  4 |  2.00 |  1.0773 |  1.0773 |  1.0000\n",
      "\n",
      "Verification:\n",
      "Final dₙ:          1.077319\n",
      "Final dₙ' × scale: 1.077319\n",
      "Match: True\n",
      "\n",
      "Example 3: Softmax Equivalence\n",
      "\n",
      "Softmax Equivalence:\n",
      "idx |  Standard  | Surrogate\n",
      "-----------------------------------\n",
      "  0 |  0.015219 |  0.015219\n",
      "  1 |  0.112457 |  0.112457\n",
      "  2 |  0.041371 |  0.041371\n",
      "  3 |  0.830953 |  0.830953\n",
      "\n",
      "Outputs match: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compare_softmax_denominators(x: torch.Tensor):\n",
    "    \"\"\" \n",
    "    Compares the standard softmax denominator (dₙ) with the surrogate sequence (dₙ')\n",
    "    to demonstrate their relationship.\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor of shape (N,)\n",
    "    Returns:\n",
    "        d: Standard denominators at each step\n",
    "        d_surrogate: Surrogate denominators at each step\n",
    "    \"\"\"\n",
    "    N = len(x)\n",
    "    \n",
    "    # Initialize arrays to store denominators and maxes\n",
    "    d = torch.zeros(N)          # Standard denominator sequence\n",
    "    d_surrogate = torch.zeros(N)  # Surrogate denominator sequence\n",
    "    m = torch.zeros(N)          # Running maximum values\n",
    "    \n",
    "    # Global maximum (used for standard sequence)\n",
    "    m_global = torch.max(x)\n",
    "    \n",
    "    # Compute both sequences\n",
    "    for i in range(N):\n",
    "        # Update running maximum\n",
    "        m[i] = torch.max(x[:i+1])\n",
    "        \n",
    "        # Standard denominator sequence using global max\n",
    "        d[i] = torch.sum(torch.exp(x[:i+1] - m_global))\n",
    "        \n",
    "        # Surrogate denominator sequence using running max\n",
    "        d_surrogate[i] = torch.sum(torch.exp(x[:i+1] - m[i]))\n",
    "        \n",
    "    return d, d_surrogate, m, m_global\n",
    "\n",
    "def analyze_sequences(x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Analyzes and prints detailed comparison of standard vs surrogate sequences.\n",
    "    \"\"\"\n",
    "    d, d_surrogate, m, m_global = compare_softmax_denominators(x)\n",
    "    \n",
    "    print(\"\\nInput sequence:\", x.numpy())\n",
    "    print(\"\\nRunning maximum (mᵢ):\", m.numpy())\n",
    "    print(\"Global maximum (mₙ):\", m_global.item())\n",
    "    \n",
    "    print(\"\\nStep-by-step comparison:\")\n",
    "    print(\"idx | x[i] |    dᵢ   |   dᵢ'   | Scale Factor\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        # Scale factor between d and d'\n",
    "        scale = torch.exp(m_global - m[i])\n",
    "        print(f\"{i:3d} | {x[i]:5.2f} | {d[i]:7.4f} | {d_surrogate[i]:7.4f} | {scale:7.4f}\")\n",
    "    \n",
    "    # Verify final values match after scaling\n",
    "    final_scale = torch.exp(m_global - m[-1])\n",
    "    scaled_final_d_surrogate = d_surrogate[-1] * final_scale\n",
    "    \n",
    "    print(\"\\nVerification:\")\n",
    "    print(f\"Final dₙ:          {d[-1]:.6f}\")\n",
    "    print(f\"Final dₙ' × scale: {scaled_final_d_surrogate:.6f}\")\n",
    "    print(f\"Match: {torch.allclose(d[-1], scaled_final_d_surrogate)}\")\n",
    "\n",
    "# Example 1: Simple increasing sequence\n",
    "print(\"\\nExample 1: Simple increasing sequence\")\n",
    "x1 = torch.tensor([1.0, 3.0, 5.0])\n",
    "analyze_sequences(x1)\n",
    "\n",
    "# Example 2: Sequence with varying patterns\n",
    "print(\"\\nExample 2: Varying sequence\")\n",
    "x2 = torch.tensor([3, 1, 4, 7, 2])\n",
    "analyze_sequences(x2)\n",
    "\n",
    "def demonstrate_softmax_equivalence(x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Demonstrates that both sequences lead to the same softmax probabilities.\n",
    "    \"\"\"\n",
    "    N = len(x)\n",
    "    \n",
    "    # Standard softmax\n",
    "    m_global = torch.max(x)\n",
    "    exp_x = torch.exp(x - m_global)\n",
    "    d_global = torch.sum(exp_x)\n",
    "    softmax_standard = exp_x / d_global\n",
    "    \n",
    "    # Softmax using surrogate sequence\n",
    "    m_local = torch.max(x)  # In this case same as global since we're at the end\n",
    "    exp_x_surrogate = torch.exp(x - m_local)\n",
    "    d_surrogate = torch.sum(exp_x_surrogate)\n",
    "    softmax_surrogate = exp_x_surrogate / d_surrogate\n",
    "    \n",
    "    print(\"\\nSoftmax Equivalence:\")\n",
    "    print(\"idx |  Standard  | Surrogate\")\n",
    "    print(\"-\" * 35)\n",
    "    for i in range(N):\n",
    "        print(f\"{i:3d} | {softmax_standard[i]:9.6f} | {softmax_surrogate[i]:9.6f}\")\n",
    "    \n",
    "    print(f\"\\nOutputs match: {torch.allclose(softmax_standard, softmax_surrogate)}\")\n",
    "\n",
    "# Demonstrate softmax equivalence\n",
    "print(\"\\nExample 3: Softmax Equivalence\")\n",
    "x3 = torch.tensor([1.0, 3.0, 2.0, 5.0])\n",
    "demonstrate_softmax_equivalence(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991452300000001"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
